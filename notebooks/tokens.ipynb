{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmorrissey/envs/plutonium_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "WARNING: You are not running on GPU so this may be slow.\n",
      "If on Google Colab, go to top menu > Runtime > Change runtime type > Hardware accelerator > 'GPU' and rerun the notebook.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "pubmed = load_dataset(\n",
    "    'pubmed_qa',\n",
    "    'pqa_labeled',\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "limit = 384\n",
    "\n",
    "def chunker(contexts: list):\n",
    "    chunks = []\n",
    "    all_contexts = ' '.join(contexts).split('.')\n",
    "    chunk = []\n",
    "    for context in all_contexts:\n",
    "        chunk.append(context)\n",
    "        if len(chunk) >= 3 and len('.'.join(chunk)) > limit:\n",
    "            # surpassed limit so add to chunks and reset\n",
    "            chunks.append('.'.join(chunk).strip()+'.')\n",
    "            # add some overlap between passages\n",
    "            chunk = chunk[-2:]\n",
    "    # if we finish and still have a chunk, add it\n",
    "    if chunk is not None:\n",
    "        chunks.append('.'.join(chunk))\n",
    "    return chunks\n",
    "\n",
    "data = []\n",
    "for record in pubmed:\n",
    "    chunks = chunker(record['context']['contexts'])\n",
    "    for i, context in enumerate(chunks):\n",
    "        data.append({\n",
    "            'id': f\"{record['pubid']}-{i}\",\n",
    "            'context': context\n",
    "        })\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# check device being run on\n",
    "if device != 'cuda':\n",
    "    print(\"==========\\n\"+\n",
    "          \"WARNING: You are not running on GPU so this may be slow.\\n\"+\n",
    "          \"If on Google Colab, go to top menu > Runtime > Change \"+\n",
    "          \"runtime type > Hardware accelerator > 'GPU' and rerun \"+\n",
    "          \"the notebook.\\n==========\")\n",
    "\n",
    "dense_model = SentenceTransformer(\n",
    "    'msmarco-bert-base-dot-v5',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "emb = dense_model.encode(data[0]['context'])\n",
    "dim = dense_model.get_sentence_embedding_dimension()\n",
    "\n",
    "from splade.models.transformer_rep import Splade\n",
    "\n",
    "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "sparse_model = Splade(sparse_model_id, agg='max')\n",
    "sparse_model.to(device)  # move to GPU if possible\n",
    "sparse_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmorrissey/envs/plutonium_env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)\n",
    "\n",
    "sample = data[0]['context']\n",
    "splade_inputs = tokenizer(sample, return_tensors='pt')\n",
    "\n",
    "# creates sparse vectors\n",
    "with torch.no_grad():\n",
    "    sparse_emb = sparse_model(\n",
    "        d_kwargs=splade_inputs.to(device)\n",
    "    )['d_rep'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "# pineconde expects dictionary style format for sparse vectors\n",
    "\n",
    "non_zero_indices = sparse_emb.nonzero().squeeze().cpu().tolist()\n",
    "print(len(non_zero_indices))\n",
    "values = sparse_emb[non_zero_indices].cpu().tolist()\n",
    "sparse = {\"indices\": non_zero_indices, \"values\": values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2token = {idx: token for token, idx in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dict_tokens = {\n",
    "    idx2token[idx]: round(weight, 2) for idx, weight in zip(indices, values)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9607, 1.0227527618408203)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_indices[100], values[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'veins': 1.02}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{idx2token[non_zero_indices[100]]: round(values[100], 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6246443390846252,\n",
       " 0.45678940415382385,\n",
       " 0.3088974952697754,\n",
       " 0.15812599658966064,\n",
       " 0.07194814831018448,\n",
       " 0.6496520042419434,\n",
       " 0.9411975145339966,\n",
       " 0.3161492645740509,\n",
       " 0.759763777256012,\n",
       " 1.9501705169677734,\n",
       " 0.3237403333187103,\n",
       " 0.3950244188308716,\n",
       " 0.23536957800388336,\n",
       " 0.2457110732793808,\n",
       " 0.42533791065216064,\n",
       " 1.9602453708648682,\n",
       " 0.6289498805999756,\n",
       " 0.42441168427467346,\n",
       " 0.018046118319034576,\n",
       " 0.19568762183189392,\n",
       " 0.6684799790382385,\n",
       " 0.8162305355072021,\n",
       " 1.0954256057739258,\n",
       " 0.1979701966047287,\n",
       " 0.22766441106796265,\n",
       " 0.013306856155395508,\n",
       " 0.904829740524292,\n",
       " 0.6024833917617798,\n",
       " 0.6100096106529236,\n",
       " 0.03979775682091713,\n",
       " 0.12952309846878052,\n",
       " 0.023475682362914085,\n",
       " 0.3975697159767151,\n",
       " 1.2144676446914673,\n",
       " 0.7056940793991089,\n",
       " 1.5106241703033447,\n",
       " 0.5332852602005005,\n",
       " 0.49861764907836914,\n",
       " 0.4658374786376953,\n",
       " 0.07503432780504227,\n",
       " 1.6885474920272827,\n",
       " 0.2525480091571808,\n",
       " 0.03533470630645752,\n",
       " 0.3232708275318146,\n",
       " 1.3433905839920044,\n",
       " 0.3039570748806,\n",
       " 0.013606893830001354,\n",
       " 0.6245615482330322,\n",
       " 0.01726490817964077,\n",
       " 1.1572377681732178,\n",
       " 0.4423246383666992,\n",
       " 0.42209091782569885,\n",
       " 1.3138160705566406,\n",
       " 0.051650792360305786,\n",
       " 0.4131581485271454,\n",
       " 0.0034907853696495295,\n",
       " 0.5426619648933411,\n",
       " 0.45670393109321594,\n",
       " 0.9155899882316589,\n",
       " 0.2175244837999344,\n",
       " 0.11264970898628235,\n",
       " 0.3476944863796234,\n",
       " 0.3003694713115692,\n",
       " 0.09560265392065048,\n",
       " 0.12621095776557922,\n",
       " 0.900026261806488,\n",
       " 0.39793914556503296,\n",
       " 0.11865357309579849,\n",
       " 0.0012638922780752182,\n",
       " 0.08769600093364716,\n",
       " 0.304739385843277,\n",
       " 0.9953426718711853,\n",
       " 0.3458155691623688,\n",
       " 0.35651591420173645,\n",
       " 0.9260972738265991,\n",
       " 0.15279145538806915,\n",
       " 0.06358940154314041,\n",
       " 0.08317626267671585,\n",
       " 0.35262244939804077,\n",
       " 0.08260074257850647,\n",
       " 0.19066177308559418,\n",
       " 1.1524649858474731,\n",
       " 0.45077598094940186,\n",
       " 0.4753192663192749,\n",
       " 0.02695303224027157,\n",
       " 3.016679286956787,\n",
       " 0.1974690556526184,\n",
       " 0.15476751327514648,\n",
       " 0.38164710998535156,\n",
       " 1.0277020931243896,\n",
       " 0.5071762204170227,\n",
       " 0.47754159569740295,\n",
       " 0.24300870299339294,\n",
       " 0.8693495392799377,\n",
       " 0.12192294001579285,\n",
       " 0.14416617155075073,\n",
       " 0.14129532873630524,\n",
       " 0.027814483270049095,\n",
       " 0.10156695544719696,\n",
       " 0.21782644093036652,\n",
       " 1.0227527618408203,\n",
       " 1.1363974809646606,\n",
       " 1.4537827968597412,\n",
       " 0.14175021648406982,\n",
       " 0.007140237372368574,\n",
       " 0.5177187919616699,\n",
       " 0.27814263105392456,\n",
       " 0.13304993510246277,\n",
       " 0.022451037541031837,\n",
       " 0.01368003711104393,\n",
       " 0.5391485691070557,\n",
       " 0.7020854949951172,\n",
       " 0.13944311439990997,\n",
       " 0.1596939116716385,\n",
       " 0.04515159875154495,\n",
       " 0.03438388556241989,\n",
       " 0.9988209009170532,\n",
       " 0.3180454671382904,\n",
       " 0.12348055839538574,\n",
       " 2.2563421726226807,\n",
       " 1.5308406352996826,\n",
       " 0.4387586712837219,\n",
       " 0.3514258563518524,\n",
       " 0.12914349138736725,\n",
       " 0.2948996424674988,\n",
       " 0.0278527420014143,\n",
       " 0.1314225047826767,\n",
       " 0.5072862505912781,\n",
       " 2.953413963317871,\n",
       " 0.20614483952522278,\n",
       " 0.18729345500469208,\n",
       " 0.006644536275416613,\n",
       " 0.19079850614070892,\n",
       " 0.2940412163734436,\n",
       " 0.24576273560523987,\n",
       " 0.10686618834733963,\n",
       " 0.526634156703949,\n",
       " 1.115312933921814,\n",
       " 0.28538233041763306,\n",
       " 0.22623345255851746,\n",
       " 0.012699447572231293,\n",
       " 1.4963693618774414,\n",
       " 0.46360334753990173,\n",
       " 2.356555461883545,\n",
       " 1.4595332145690918,\n",
       " 0.08020822703838348,\n",
       " 1.8086856603622437,\n",
       " 0.35684043169021606,\n",
       " 1.5568329095840454,\n",
       " 1.3857107162475586,\n",
       " 0.3467239439487457,\n",
       " 0.5948582291603088,\n",
       " 0.0012728216825053096,\n",
       " 0.3454737067222595,\n",
       " 0.8152064681053162,\n",
       " 1.3145086765289307,\n",
       " 0.201742023229599,\n",
       " 0.7402419447898865,\n",
       " 0.34606507420539856,\n",
       " 0.03515402972698212,\n",
       " 0.09972937405109406,\n",
       " 0.6928016543388367,\n",
       " 0.07752572745084763,\n",
       " 0.1303844153881073,\n",
       " 0.26102912425994873,\n",
       " 0.018996920436620712,\n",
       " 0.5055299997329712,\n",
       " 0.33787935972213745,\n",
       " 1.6032907962799072,\n",
       " 1.6398859024047852,\n",
       " 1.3861643075942993,\n",
       " 1.4482746124267578,\n",
       " 0.35941874980926514,\n",
       " 2.27683162689209]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plutonium_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
